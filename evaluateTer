#!/usr/bin/env python
import argparse # optparse is deprecated
import sys
from itertools import islice # slicing for iterators
from collections import defaultdict

def word_Edits(h, ref):
	# use in reg TER
	remainRef   = []
	toRemoveRef = []
	remainHL    = []	
	#toDelete    = []
	#modifiedH   = []
	#toSub       = []
	#toInsert    = []
	#wWMatch     = 0

	# Pre Look 
	#if len(h) == len(ref):
	#	for wH, wR in zip(h,ref):
	#		if wH is wR:
	#			wWMatch +=1

	#if wWMatch == len(ref):
	#	return 0	# Ref and h exact match "perfect" score
				
	# account for deletions first
	#for wordH in h:
	#	if wordH not in ref:
	#		for wordR in ref:
	#			if wordR.find(wordH) == -1: # not substring
	#				toDelete.append(wordH)
	#			else:
	#				toSub.append(wordH)

	# Should leave us with h less than ref 
	#for word in h:
	#	if word not in toDelete:
	#		modifiedH.append(word) 
	
	#wWMatch = 0
	#for wH, wR in zip(modifiedH, ref):
	#	if wH is wR:
	#		wWMatch += 1

	#if wWMatch == len(ref):
	#	return len(toDelete) # word for word match "perfect" score of zero		
	
	#for wordR in ref:
	#	if wordR not in modifiedH:
	#		if wordR not in toSub:
	#			toInsert.append(wordR) # word needs to be inserted
	
	#return len(toInsert) + len(toSub) + len(toDelete)

	for word in h:
		if word not in ref:
			remainHL.append(word) # these end up being substituion or deletions
		else: # word is in ref
			toRemoveRef.append(word)

	for word in ref:
		if word not in toRemoveRef:
			remainRef.append(word) # the are insertions needed

	for wordR in remainRef:
		for wordH in remainHL:
			# subsstring found, since it does not use any added resource
			# we persume this is a substitution, else substitution have to 
			# account for a delete and insert. 
			if wordR.find(wordH) > -1: 
				remainRef.remove(wordR)
				break

	TotalEdits = len(remainRef) + len(remainHL)

	return TotalEdits

def main():
	parser = argparse.ArgumentParser(description='Evaluate translation hypotheses.')
	parser.add_argument('-i', '--input', default='data/hyp1-hyp2-ref', help='input file (default data/hyp1-hyp2-ref)')
	parser.add_argument('-n', '--num_sentences', default=None, type=int, help='Number of hypothesis pairs to evaluate')
	# note that if x == [1, 2, 3], then x[:None] == x[:] == x (copy); no need for sys.maxint
	opts = parser.parse_args()

    # we create a generator and avoid loading all sentences into a list
	def sentences():
		with open(opts.input) as f:
			for pair in f:
				yield [sentence.strip().split() for sentence in pair.split(' ||| ')]
 
    # note: the -n option does not work in the original code
	
	alpha = .25
	for h1, h2, ref in islice(sentences(), opts.num_sentences):
		rset = set(ref)
		h1_edits = word_Edits(h1, rset)
		h2_edits = word_Edits(h2, rset)
		# Used in reg Ter
		h1_prec = h1_edits/float(len(h1))
		h1_recall = h1_edits/float(len(ref))
		h2_prec = h2_edits/float(len(h2))
		h2_recall = h2_edits/float(len(ref))
		l1 = 0 
		l2 = 0
		#l1 = h1_edits/float(len(rset))
		#l2 = h2_edits/float(len(rset))
		# Used in reg Ter
		if ((1-alpha)*h1_recall + alpha*h1_prec) != 0:
			l1 = h1_prec * h1_recall/((1-alpha)*h1_recall + alpha*h1_prec)
		if ((1-alpha)*h2_recall + alpha*h2_prec) != 0:
			l2 = h2_prec * h2_recall/((1-alpha)*h2_recall + alpha*h2_prec)
		print(1 if l2 > l1 else # \begin{cases}
			(0 if l1 == l2
			else -1)) # \end{cases}


# convention to allow import of this file as a module
if __name__ == '__main__':
    main()
